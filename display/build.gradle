//解决windows下 gradel文件名过长的问题
buildscript {
    repositories {
        maven {
            url "https://plugins.gradle.org/m2/"
        }
    }
    dependencies {
        classpath "gradle.plugin.ua.eshepelyuk:ManifestClasspath:1.0.0"
        classpath 'com.github.jengelman.gradle.plugins:shadow:2.0.4'
    }
}
apply plugin: "ua.eshepelyuk.ManifestClasspath"
apply plugin: 'com.github.johnrengelman.shadow'

version '1.0.0'
apply plugin: 'java' //指定java插件
apply plugin: 'scala' //指定scala插件

sourceSets {
    main {
        scala {
            srcDirs = ['src/main/scala','src/main/java']
        }
        java {
            srcDirs = [ ]
        }
    }
}

repositories {
    mavenLocal()
    //由于国内可能无法正常访问maven中心库，这里就填写了两个基本上能正常访问的maven库地址
    maven {
        url 'http://maven.aliyun.com/nexus/content/groups/public/'
    }
    maven {
        url 'https://repository.cloudera.com/artifactory/cloudera-repos/'
    }
    mavenCentral()
}

ext {
    scalaVersion = '2.11'
    sparkVersion = '3.0.0'
    jarName=''
}
dependencies {
    compile('mysql:mysql-connector-java:5.1.48')

    compile 'commons-codec:commons-codec:1.10'

    // https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common
    compile group: 'org.apache.hadoop', name: 'hadoop-common', version: '3.0.0-cdh6.2.1'

// https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-client
    compile group: 'org.apache.hadoop', name: 'hadoop-client', version: '3.0.0-cdh6.2.1'
    // https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-hdfs
    compile group: 'org.apache.hadoop', name: 'hadoop-hdfs', version: '3.0.0-cdh6.2.1'


    // https://mvnrepository.com/artifact/org.apache.spark/spark-core

    // https://mvnrepository.com/artifact/org.apache.spark/spark-core
    compile group: 'org.apache.spark', name: 'spark-core_2.11', version: '2.4.0-cdh6.2.1'
    // https://mvnrepository.com/artifact/org.apache.spark/spark-sql
    compile group: 'org.apache.spark', name: 'spark-sql_2.11', version: '2.4.0-cdh6.2.1'


    compile "org.scala-lang:scala-library:$scalaVersion"
    compile 'org.apache.poi:poi:3.17'
    compile 'org.apache.poi:poi-ooxml:3.17'

    //remote ssh
    compile 'ch.ethz.ganymed:ganymed-ssh2:262'
    compile 'commons-io:commons-io:2.6'

    // https://mvnrepository.com/artifact/org.apache.hive/hive-jdbc
    compile group: 'org.apache.hive', name: 'hive-jdbc', version: '2.1.1-cdh6.2.1'

}
jar {
//后缀名
    archiveBaseName.set('LTPC')
    archiveAppendix.set('DAQ')
    archiveVersion.set('2.1')
    archiveClassifier.set('release')
    archiveExtension.set('jar')
    jarName="${archiveBaseName.get()}-${archiveAppendix.get()}-${archiveVersion.get()}-${archiveClassifier.get()}.${archiveExtension.get()}"
    manifest {
        attributes(
                "Manifest-Version": 1.0,
                "Main-Class": 'com.wy.Main')

    }
}
shadowJar {
    archiveBaseName.set('LTPC')
    archiveAppendix.set('DAQshadow')
    archiveVersion.set('2.1')
    archiveClassifier.set('release')
    archiveExtension.set('jar')
    manifest {
        attributes 'Main-Class': 'com.wy.Main'
    }
    zip64 true
}
tasks.withType(JavaCompile) {
    options.encoding = "UTF-8"
}
tasks.withType(ScalaCompile) {
    options.encoding = "UTF-8"
}

//task clearJar(type: Delete) {
//    delete ("$buildDir\\libs\\lib")
//    delete ("C:\\Users\\dgbtds\\Desktop\\LtpcExe\\MyApp\\lib")
//    delete fileTree("$buildDir\\libs") {
//        include '*.jar'
//    }
//    delete fileTree("C:\\Users\\dgbtds\\Desktop\\LtpcExe\\MyApp") {
//        include '*.jar'
//    }
//}
////设置clear顺序优先
//assemble.mustRunAfter clearJar
//// 将依赖包复制到lib目录
//task copyLib(type: Copy, dependsOn: 'clearJar') {
//    from configurations.runtime
//    into "$buildDir\\libs\\lib"
//    into "C:\\Users\\dgbtds\\Desktop\\LtpcExe\\MyApp\\lib"
//}
//task copyJar(type: Copy, dependsOn: 'clearJar') {
//    from("$buildDir\\libs\\$jarName")
//    into "C:\\Users\\dgbtds\\Desktop\\LtpcExe\\MyApp"
//}
//task release(type: Copy, dependsOn: [clearJar,copyLib,copyJar,build])